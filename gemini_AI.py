import streamlit as st
import base64
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
#from langchain.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os
from langchain_community.vectorstores import FAISS

st.set_page_config(page_title="BidBooster", layout="wide")

st.markdown("""
## ãƒ“ãƒƒãƒ‰ãƒ–ãƒ¼ã‚¹ã‚¿ãƒ¼ ğŸ¤—ğŸ’¬: RFP é–¢é€£ã®è³ªå•ã«ç­”ãˆã¾ã™.

### ä½¿ã„æ–¹ï¼Ÿ

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨å¯¾è©±ã™ã‚‹ã«ã¯ã€æ¬¡ã®ç°¡å˜ãªæ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ã€‚
1. **RFP ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€[é€ä¿¡ã—ã¦å‡¦ç†] ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™** (æ³¨æ„: åŸºæœ¬ LLM ãƒ¢ãƒ‡ãƒ«ã¯ LCBO ESG RFP ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦å¾®èª¿æ•´ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœã¯ä»–ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)ã€‚
2. **è³ªå•ã™ã‚‹:** æ–‡æ›¸ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€æ­£ç¢ºãªå›ç­”ã‚’å¾—ã‚‹ãŸã‚ã«ãã®å†…å®¹ã«é–¢é€£ã™ã‚‹è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚
3. ã‚ˆã‚Šè‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã€**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ˜ç¢ºã‹ã¤å®Œå…¨ã§ã‚ã‚‹**ã“ã¨ã‚’ç¢ºèªã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚
""")

st.image("https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExcjl2dGNiYThobHplMG81aGNqMjdsbWwwYWJmbTBncGp6dHFtZTFzMSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/CGP9713UVzQ0BQPhSf/giphy.gif", width=50)

# This is the first API key input; no need to repeat it in the main function.
#api_key = st.text_input("Enter your Google API Key:", type="password", key="api_key_input")

api_key = st.secrets['GEMINI_API_KEY']
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
    chunks = text_splitter.split_text(text)
    return chunks

def get_vector_store(text_chunks, api_key):
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
    vector_store.save_local("faiss_index")

def get_conversational_chain():
    prompt_template = """
    æä¾›ã•ã‚ŒãŸæ–‡è„ˆã‹ã‚‰å¯èƒ½ãªé™ã‚Šè©³ç´°ã«ã€ä¸å¯§ãªæ–¹æ³•ã§æ—¥æœ¬èªã§è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚ç­”ãˆãŒãã†ã§ãªã„å ´åˆã¯ã€å¿…ãšã™ã¹ã¦ã®è©³ç´°ã‚’è¦ç´„ã—ãŸå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒæä¾›ã•ã‚ŒãŸå ´åˆã¯ã€ã€Œãã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ç­”ãˆãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ã ã‘è¨€ã†ã ã‘ã§ã€é–“é•ã£ãŸç­”ãˆã‚’æä¾›ã—ãªã„ã§ãã ã•ã„ã€‚ãã—ã¦ã€å›ç­”ã‚’ã‚ˆã‚Šé©åˆ‡ãªå½¢å¼ã«ã™ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ãªã„ã§ãã ã•ã„ã€‚ã‚ˆã‚Šé©åˆ‡ãªæ–¹æ³•ã§è¦ç´„ã—ã¦ã‹ã‚‰ã€ç­”ãˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
    
    ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆ:\n {context}?\n
    è³ªå•: \n{question}\n .æ—¥æœ¬èªã§è¦ç´„ã—ãŸå›ç­”ã‚’æä¾›ã—ã€ã‚ˆã‚Šé©åˆ‡ãªå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚å¿…è¦ã«å¿œã˜ã¦ç®‡æ¡æ›¸ãã‚’è¿½åŠ ã—ã¾ã™ã€‚ RFP ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ã‚‹ã®ã§ã¯ãªãã€è¦ç´„ã—ã¦ãã ã•ã„ã€‚

    Answer:
    """
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3, google_api_key=api_key)
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    print("Prompt ***** --->", prompt)
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
    return chain

def user_input(user_question, api_key):
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    #new_db = FAISS.load_local("faiss_index", embeddings)
    new_db = FAISS.load_local("faiss_index", embeddings,allow_dangerous_deserialization=True)
    docs = new_db.similarity_search(user_question)
    chain = get_conversational_chain()
    response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
    st.write("ãƒ“ãƒƒãƒ‰ãƒ–ãƒ¼ã‚¹ã‚¿ãƒ¼: ", response["output_text"])

def main():
    st.header("è³ªå•ã—ã¦ãã ã•ã„...")

    user_question = st.text_input("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è³ªå•ã™ã‚‹", key="user_question")

    if user_question and api_key:  # Ensure API key and user question are provided
        user_input(user_question, api_key)

    with st.sidebar:
        st.title("ãƒ“ãƒƒãƒ‰ãƒ–ãƒ¼ã‚¹ã‚¿ãƒ¼ ğŸ¤—ğŸ’¬")
        pdf_docs = st.file_uploader("PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€Œé€ä¿¡ã—ã¦å‡¦ç†ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚", accept_multiple_files=True, key="pdf_uploader")
        if st.button("é€ä¿¡ã—ã¦å‡¦ç†ã™ã‚‹", key="process_button") and api_key:  # Check if API key is provided before processing
            with st.spinner("å‡¦ç†..."):
                raw_text = get_pdf_text(pdf_docs)
                text_chunks = get_text_chunks(raw_text)
                get_vector_store(text_chunks, api_key)
                st.success("çµ‚ã‚ã‚Š")

        st.image("https://media.tenor.com/s1Y9XfdN08EAAAAi/bot.gif", width=200)


if __name__ == "__main__":
    main()
